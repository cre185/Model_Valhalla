name,model_name,logo,official_website,description,document_name,document_website,license,released_time
mistral_7b,mistral_7b,logo/mistral_7b.png,https://mistral.ai/news/announcing-mistral-7b/,Mistral-7B是一个拥有73亿参数的语言模型，由欧洲的Mistral AI开发和发布。它使用了组查询注意力和滑动窗口注意力机制，以实现高效和高性能的文本和代码生成。\nMistral-7B的资源消耗很低，只需要6GB显存，可在MacBook上流畅运行。Mistral-7B适用于文本摘要、分类、文本补全、代码补全等各种任务。,Mistral 7B,https://arxiv.org/abs/2310.06825,Apache-2.0,2023-10-16
qwen_7b_chat,qwen_7b_chat,logo/qwen_7b_chat.jpg,https://github.com/QwenLM/Qwen,通义千问-7B（Qwen-7B）是阿里云研发的通义千问大模型系列的70亿参数规模的模型。Qwen-7B是基于Transformer的大语言模型，在超大规模的预训练数据上进行训练得到。\n预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。同时，在Qwen-7B的基础上，我们使用对齐机制打造了基于大语言模型的AI助手Qwen-7B-Chat。,Qwen Technical Report,https://arxiv.org/abs/2309.16609,Apache-2.0,2023-9-24
vicuna_13b_v15,vicuna_13b_v15,logo/vicuna_7b.png,https://lmsys.org/blog/2023-03-30-vicuna/,vicuna_13b_v15是一个基于transformer架构的自回归语言模型，由LMSYS开发，用于聊天助手的研究和应用。它是在LLaMA 2的基础上，利用ShareGPT.com收集的约125K个用户共享的对话进行监督指令微调而得到的。它支持最高16K的上下文输入，能够生成流畅、有趣和有帮助的回答。,Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena,https://arxiv.org/abs/2306.05685,Apache-2.0,2023-6-18
vicuna_7b,vicuna_7b,logo/vicuna_7b.png,https://lmsys.org/blog/2023-03-30-vicuna/,Vicuna-7B是一个基于LLaMA的聊天机器人模型，由LMSYS开发，拥有73亿参数。它使用了ShareGPT的数据进行微调，能够生成流畅和有趣的对话。\n它在多个聊天机器人的评测中表现出色，超过了更大的模型。它的资源消耗很低，只需要6GB的显存，可以在MacBook上运行。它是一个开源的模型，使用Apache 2.0协议。,Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena,https://arxiv.org/abs/2306.05685,Apache-2.0,2023-6-18
zephyr_7b,zephyr_7b,logo/zephyr_7b.png,https://github.com/huggingface/alignment-handbook,Zephyr_7b是一款由Zephyr Technologies开发的语言模型，它可以生成各种类型的文本，如诗歌、故事、代码、论文、歌曲、名人模仿等。Zephyr_7b的特点是创造性和多样性，\n它可以根据用户的输入和偏好来调整自己的风格和内容。Zephyr_7b的目标是为用户提供有趣和有用的文本，同时保证文本的质量和合理性。Zephyr_7b是一款先进和创新的语言模型，它展示了人工智能在自然语言处理领域的潜力和可能性。,Zephyr: Direct Distillation of LM Alignment,https://arxiv.org/abs/2310.16944,Apache-2.0,2023-10-11
