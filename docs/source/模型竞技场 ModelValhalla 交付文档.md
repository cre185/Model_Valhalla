# 模型竞技场 ModelValhalla 交付文档

> 姚润茂 方钧同 李科霖 钟健坤

[TOC]

## 交付产品

### 产品访问方式



### 仓库链接

Github仓库：https://github.com/cre185/Model_Valhalla

## 产品目标

### 功能目标

### 性能需求

### 预期指标

## 开发组织管理

### 过程管理

项目开发主要开始于第七周，整体开发工作基本按照项目初期的指定的开发时间线进行，部分功能点的开发顺序因实际需要做了一定调整。具体开发时间线如下：

- 7-8周完成开发环境的搭建，创建前后端通信连接，并完成用户注册和登录功能（包括用户中心的个人信息及安全信息修改）；
- 9-10周完成主要页面排行榜相关功能的开发，包括排序、筛选、查看模型详情等功能，此外还完成了对抗评测的初步版本；
- 11周完善了对抗评测，补全了另一功能主管评测，并对已有功能进行了一定的bug修复及UI优化；
- 12-13周完成了数据页面相关功能的开发，在排行榜功能基础上增加了用户自定义标签和模型表现可视化等特色功能
- 14-15周集中解决了尚未完成的任务：在功能方面完成了用户个人中心和站内信的相关实现，测试方面主要集中于性能测试，并对已有功能进行了bug修复和UI优化。在这一阶段中，同时完成了部署的相关工作。

在开发的过程中，虽然因为计划外功能的加入以及组员身体原因等因素，总体开发的完成稍慢与原定计划，但由于组员之间积极沟通，任何与开发进度相关的变更都会在集中开发会议中进行商讨，因此开发计划的跟进始终在可控的范围内。此外，我们也在迭代过程中积极听取助教团队的意见，并与之进行了充分的沟通讨论，在补足功能的同时，也在分支管理这一我们相对不熟悉的领域进行了较大的改善。从最初的所有人共享一个开发分支，到各组员独立的开发分支，再到基于功能点的开发分支，项目的分支管理逐渐趋于规范化。

总体的开发迭代共分三轮，第一轮迭代为6-8周，完成了用户注册和登录功能后的应用初具雏形，此为发布的版本一；9-11周完成了核心功能排行榜和测试，应用具备了作为开放大语言模型能力排行榜的基本功能，此为发布的版本二；12-13周完善了数据集功能并完成了bug修复和UI优化，此时的应用已经可以正常使用，此为发布的版本三；14-15周对拓展功能进行了实现，完成了性能测试和部署的相关工作，此为发布的最终版本。

### 人员分工

### 开发环境

#### 前端：

前端主要使用Vue.js，通过组件化思想， 将页面拆分为独立组件，方便维护和服用。 通过 Vue 的数据绑定机制和指令系统，我们可以简化 DOM 操作，提高团队的开发效率。

项目使用了字节开发的Arco Design库，我们利用其提供的丰富组件，实现了较为美观实用的UI界面。此外，对于其中一些不能达到我们需求的组件，我们也对齐进行了一定的调整，并最终应用于我们的项目中。

项目整体采用npm作为包管理工具，路由方面的实现通过Vue.router实现。请求的发送通过axios实现，其强大的interceptor功能便于我们对数据包进行统一的前处理和后处理。存储管理使用了pinia，其模块化的特点以及响应式的api极大程度地便利了整体的开发。此外，使用的库还包括绘制图标的chart.js，统一时间管理机制的mitt以及对数据集(.csv)进行处理的papaparse。

#### 后端：

后端使用django框架及其扩展包django-rest-framework，实现了对前端的数据请求的响应。通过django框架的ORM机制，可以轻松实现对数据库的操作。  
DRF框架提供了一套强大的序列化工具以及视图类，保证接口RESTful风格，同时也极大的简化了开发难度。  
项目使用pip和conda作为包管理工具，借助PyJwt实现了用户登录的token验证，使用了Django-cors-headers解决了跨域问题。DRF内置的更强大的Response对象让后端返回的响应更加灵活，APIClient测试工具则使得测试工作更加便捷。  

### 配置管理

项目的版本控制和变更管理主要通过Git实现。

分支管理在进行过两次优化之后，主要采用基于功能的分支管理策略，具体如下：

- 项目的后端由于仅由钟健坤同学开发，因此独占backend分支。前端的主分支为main。
- 每当需要开发新的主要功能点时，从main分支拉取新分支并命名为对应的功能点（如ranking）。
- 小组成员分别开发主要功能点的具体功能时，需从主功能点拉取新分支并命名（如ranking_details），开发完成后合并到主要功能点分支。
- 主要功能点所有具体功能开发完成后，对这一功能点的相关内容进行测试，确认无误后合并到主分支。

代码审查主要通过eslint进行了规范性检查，具体可参照代码编写规范文档。

我们对代码进行的自动化测试主要为单元测试，具体的测例编写随功能开发同步进行，最终覆盖率可达97%。

版本号主要依据最初指定的开发时间线确定，具体格式为`x.y.z`，其中x为主要版本号，可参阅过程管理部分的内容；y为次版本号，记载了当前主版本中已经完成的主要功能点的个数；z则是修订号，在对当前版本进行bug修复和UI优化后会进行更新。

## 系统设计

### 前端交互

#### 界面设计原则

1. **一致性：** 前端界面的布局基本都采用上下结构，页面上部分是简单组件，页面中下部分是主要组件，界面元素的设计在整个应用程序中保持一致，这样更有助于用户理解和掌握我们网页的使用方式。
2. **可用性：** 我们的界面设计简单直观，基本都是简单直接的按钮操作，这样使得用户能够轻松、有效地完成任务。
3. **反馈性：** 在用户执行一些操作时，我们会通过界面的反馈及时告知用户操作的结果，例如“登录成功”、“登录过期”等全局提醒，这些反馈可以帮助用户了解其行为的后果。
4. **可导航性：** 我们在界面侧边提供清晰、一致的导航结构，使用户能够轻松找到所需的信息和功能，有助于用户快速了解网页的结构和布局。
5. **美观性：** 我们尽量使界面外观吸引人，如考虑一致美观的颜色搭配、字体选择、图标设计等，以创造愉悦的用户体验，并且我们没有位了一味追求美观而牺牲功能性。
6. **普适性**：网页支持中英文双语，可以服务使用不同语种的用户群体。

#### 用户交互流程

##### 主页

![1](/Users/yaorunmao/Desktop/1.png)

+ 页面最上方是标题栏，标题栏左侧是项目名称，标题栏右侧依次是**切换语言按钮**、**切换暗黑/明亮模式按钮**、**用户状态**。未登录状态下用户可以通过点击主页的**Get Started**或标题栏的**您好，请先登录**进行登录。

![1](/Users/yaorunmao/Desktop/7.png)

+ 用户登录后标题栏会额外出现一个**站内信按钮**。登录后点击主页的**Get Started**会跳转到排行榜页面。
+ 页面侧边是导航栏，从上到下依次是**主页**、**排行榜**、**数据集**、**评测（包括主观评测、对抗评测）**、**个人中心（包括用户信息、用户设置）**，用户可以点击对应的选项卡跳转到相应的页面。在导航栏的右下角有一个**最小化按钮**，点击即可缩小导航栏，再次点击可以放大导航栏。

![1](/Users/yaorunmao/Desktop/8.png)

+ 鼠标悬浮在标题栏的**用户头像**上，会弹出下拉菜单，点击**用户信息**可以跳转到用户信息页，点击**用户设置**可以跳转到用户设置页，点击**退出登录**可以退出登录。

##### 登录页

![1](/Users/yaorunmao/Desktop/2.png)

![1](/Users/yaorunmao/Desktop/3.png)

+ 左侧是图片轮播组件，简单介绍网页的功能。
+ 右侧是登录组件，分为**密码登录**和**验证码登录**，前者输入账号和密码，后者输入手机号和短信验证码，之后点击**登录**按钮即可登录，如没有账号可以点击登录按钮下方的**注册账号**按钮跳转到注册页。

##### 注册页

![1](/Users/yaorunmao/Desktop/4.png)

+ 用户账号分为两种——**普通用户**和**管理员**。

![1](/Users/yaorunmao/Desktop/5.png)

+ 普通用户填写相应字段后点击**注册按钮**即可完成账号注册。

![1](/Users/yaorunmao/Desktop/6.png)

+ 管理员相比普通用户要额外填写**管理员邀请码**，完成填写后点击**注册按钮**即可完成账号注册。

##### 排行榜

![1](/Users/yaorunmao/Desktop/9.png)

+ 排行榜页面有一个欢迎页，可以通过**鼠标下滑**或点击**Get Started**进入排行榜主页

![1](/Users/yaorunmao/Desktop/10.png)

+ 页面左上方是搜索框，输入关键字后点击**搜索按钮**即可搜索模型。点击右上方的**下载**即可以`csv`格式下载排行榜。点击右上方的**齿轮**后在下拉菜单中可以选择排行榜展示的信息条目，可额外显示所有模型在特定数据集上的得分，在下拉菜单中**上下拖动**菜单项可以调整显示顺序。
+ 页面中间是排行榜，点击任何一个表头都可以**重新排序**。每个模型右侧都有**查看**按钮，点击可以查看模型详情。

![1](/Users/yaorunmao/Desktop/11.png)

+ 模型详情页包括四个标签页：**详细信息**、**数据集表现**、**对抗记录**、**讨论区**，点击模型详情页上方的**关注**即可关注该模型。
+ 在详细信息标签页可查看模型的基本信息。

![1](/Users/yaorunmao/Desktop/12.png)

+ 在数据集表现标签页可查看模型在不同数据集上的得分，可以通过上方的**筛选框**筛选数据集。

![1](/Users/yaorunmao/Desktop/13.png)

+ 在对抗记录标签页可查看与该模型相关的对抗评测记录，可以通过上方的**筛选框**筛选评测记录，可以点击每条记录前对抗详情栏的**+**来查看详细记录。

![1](/Users/yaorunmao/Desktop/14.png)

+ 在讨论区标签页可以**发表评论**、**点赞**、**点踩**、**回复评论**。

##### 数据集

![1](/Users/yaorunmao/Desktop/15.png)

+ 数据集页上方是**筛选框**，输入筛选项后点击**搜索**可以筛选数据集，点击**重置**可以清楚筛选项。先**勾选**目标数据集，然后点击**批量下载**即可下载多个数据集文件。
+ 数据集页中间展示了现有数据集条目，点击任意**表头**都可以重新排序，点击**添加标签**可以为对应数据集添加标签，点击**下载**可以下载相应数据集文件，点击**查看**可以查看数据集详情。

![1](/Users/yaorunmao/Desktop/16.png)

+ 点击数据集主页的**上传**可以上传数据集。

![1](/Users/yaorunmao/Desktop/17.png)

+ 点击数据集主页的**反馈**可以反馈数据集相关的问题。

![1](/Users/yaorunmao/Desktop/18.png)

+ 数据集详情页包括四个标签页：**详细资料**、**预览**、**测试表现**、**讨论区**，点击数据集详情页上方的**关注**即可关注该数据集。
+ 在详细资料标签页可以查看数据集详细资料。

![1](/Users/yaorunmao/Desktop/19.png)

+ 在预览标签页可以预览一小部分数据集内容。

![1](/Users/yaorunmao/Desktop/20.png)

+ 在测试表现标签页可以查看不同模型在该数据集上的得分，在右侧可视化部分可以**选择**三个模型，然后点击**确认**，即可查看得分可视化结果。

![1](/Users/yaorunmao/Desktop/21.png)

+ 在讨论区标签页可以**发表评论**、**点赞**、**点踩**、**回复评论**。

##### 主观评测

![1](/Users/yaorunmao/Desktop/22.png)

+ 主观评测页上方是主观评测规则，在页面下方分别**选择模型**、**选择主观数据集**后，点击**确认**，即可开始主观评测。

![1](/Users/yaorunmao/Desktop/23.png)

+ 点击右下方的**生成答案**可以获取模型回复，在评分部分可以**打分**，评完一题可以点击**下一题**或**上一题**切换题目，评完所有题目后可以点击**提交结果**来提交本次的评分结果。

##### 对抗评测

![1](/Users/yaorunmao/Desktop/24.png)

+ 对抗评测页上方是对抗评测规则，在页面下方**选择模型**后，点击**确认**，即可开始对抗评测。

![1](/Users/yaorunmao/Desktop/25.png)

+ 可以在输入框**直接输入问题**，也可以通过**填充**来填入预设问题，点击**发送**即可提交问题并获取模型回复。

### 后端模块
后端在django中分为了四个部分（app）：用户管理、数据集、排行榜、模型测试，主要对应我们的四个大功能部分。对于我们的项目而言，这四个部分并没有明显的主次之分，都可以算作核心模块。下面描述一下各模块的主要功能。  
#### 用户管理  
用户管理模块主要负责用户的注册、登录等基本功能，一个较重要的功能是用户之间的站内信功能。后端将每一条消息作为一个对象，另外记录每条消息对应的发送者和接收者，从而解决了群发消息的问题。  
#### 数据集  
数据集模块主要负责数据集的上传、下载、筛选等功能。数据集支持下载以及预览功能，这部分通过文件操作完成。  
#### 排行榜  
排行榜模块主要负责排行榜的展示、筛选等功能。该模块记录了所有模型在数据集上进行测试得到的结果信息，并提供了接口用于按特定标准进行筛选获取。  
#### 模型测试  
模型测试模块主要负责模型以及评测的功能。后端实现了模型在某一数据集上的自动评测，同时开放了对某一模型进行调用的接口，以便于前端进行人工评测。  
### 接口规范
由于使用了DRF框架，我们的接口规范主要遵循RESTful风格。  
REST即Representational State Transfer的缩写，提供了一组设计原则和约束条件。具体而言我们的接口满足：  
1. 以资源为基础：资源是REST架构中的核心概念，django框架中的Model刚好可以看作资源。  
2. 统一接口：对于资源的操作，我们使用统一的接口，即HTTP协议中的方法，包括`GET`、`POST`、`PATCH`、`DELETE`等。对于最基本的资源的增删改查操作，我们遵循使用`GET`方法获取资源，使用`POST`方法创建资源，使用`PATCH`方法部分更新资源，使用`DELETE`方法删除资源的规范。  
3. 无状态：对于每个请求，服务器不会记录任何状态信息，即每个请求都是独立的。  

### 数据库设计
由于我们使用的是MySQL数据库，因此数据库模式即为数据库本身。  
我们数据库中的表较多，下面边列举边介绍表之间的依赖关系。  
#### 用户管理模块  
用户管理模块中的表包括：  
* user：用户表，记录了用户的基本信息，包括用户名、密码、邮箱、手机号、用户类型等。  
* verifyemail/verifymsg：验证码表，记录了用户需要发送验证码时的验证码信息，包括验证码、验证码类型、验证码过期时间等。  
* msg/msgtarget：站内信表，msg表用于记录信息本身，msgtarget表用于记录信息的所有接收者。  
* llmsubscription/datasetsubscription：关注表，记录了用户关注的模型和数据集。这两张表依赖于dataset和llm对象。  
#### 数据集模块  
数据集部分仅有一张表，也即dataset表，记录了数据集的基本信息，包括数据集名称、数据集描述、数据集文件等。  
#### 排行榜模块  
排行榜模块中的表包括：  
* credit：评测分数表，表示某一模型在某一数据集上的得分。这个对象对于每个数据集/模型的组合恰好存在一个。注意这个对象会在创建/删除模型/数据集时自动更新。  
* llmcomment/datasetcomment：评论表，记录了用户对模型/数据集的评论。评论这一功能由于在前端页面上是随着排行榜一起展示的，故在后端也分类在排行榜模块中。这一表依赖于user、dataset、llm三种对象。  
* llmlike/datasetlike：点赞表，记录了用户对模型/数据集的评论的点赞的点赞。需要user的信息。  
#### 模型测试模块  
模型测试模块中的表包括：  
* llms：模型表，记录了模型的基本信息，包括模型名称、模型描述、模型url等。  
* battlehistory：对抗记录表，记录了不同模型之间的对抗评测记录。依赖于两个不同的llm对象。  
### 其他模块
后端的其他模块和功能均放在了utils文件夹下，目前该文件夹包含如下的若干个功能：  
* jwt/admin_required：采用jwt进行了用户的身份验证，我们的jwt包含了用户的id以及用户是否为管理员的信息。这两个模块分别提供了装饰器，用于验证请求的用户是否已经登录/为管理员。  
* auto_test：自动评测模块，用于对模型在数据集上进行自动评测以及调用模型的url生成结果。  
* elo_rating：Elo评分模块，用于计算模型之间的Elo评分，用于模型测试的对手匹配。  
* send_msg：发送手机验证码接口，通过调用阿里云的短信服务，向用户发送验证码。  
* validation_error：自定义的异常类，用于处理前端传来的数据不合法的情况，能自定义返回信息。  
* verify_dataset：数据集验证模块，用于验证数据集文件的合法性。  

## 重点和难点问题及其解决方法，以及核心算法

## 测试总结

### 基础要求

#### 功能测试

#### 性能测试
采用了Apache JMeter进行性能测试，测试的目标涵盖了四个后端模块的各种接口。  
在较高的并发量下（100个线程），后端接口的响应时间也能保持在100ms以内。延迟时间变长的一个主要原因是，list需要传输的数据以及花费的时间明显变长。  
此外，针对有关文件上传的部分我们单独进行了处理，让文件在高并发量的情况下也能保持数据库中的正确更新。  
在高并发量下，性能测试的接口调用并不能保证100%的成功率（100并发），但这是由于我们对上述的文件处理导致的结果，如果发现了文件冲突则返回错误信息。除文件外的接口均工作完全正常。  
### 提高要求

#### 单元测试
单元测试是我们项目的一大亮点，我们的单元测试相当完备，这主要是由于后端的开发是测试驱动的：我们遵循写测试->写功能->完善测试的流程，让单元测试涵盖到各种项目中的易错点，在这一过程中也保障了后端接口的质量。  
后端接口在使用git上传之前都会在单元测试中进行测试，保证了接口的正确性之后再上传。  
我们还使用了coverage工具对单元测试的覆盖率进行了统计，覆盖率达到了97%，这也是我们的单元测试能够保证项目质量的重要原因。  
## 系统部署
### 项目结构简述  
项目部署基于docker，具体关系为数据库MySQL、后端Django(DRF)、代理服务器Nginx分别位于三个容器内，前两者与后两者分别连接，与小作业保持一致。  
项目中的主要配置文件均位于backend目录下，具体位置为（相对backend目录）：  
* requirements.txt：python依赖  
* Model_Valhalla/settings_prod.py：生产环境采用的配置（指定了MySQL等）  
* nginx/model_valhalla.conf：nginx配置文件  
* Dockerfile and docker-compose.yml：docker配置文件  
* .env：MySQL环境变量配置文件  

### 部署至服务器  
项目的服务器部署依靠docker一步实现，在backend目录下执行`docker-compose up`即可。  
注意，在部署前需要确保前端的静态产生文件已经正确提供。前端得到的静态文件在本项目中为assets文件夹以及一个index.html文件，这些文件应当位于backend/build目录下。  
